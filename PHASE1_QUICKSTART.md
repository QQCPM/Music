# Phase 1 Quick Start Guide

**Goal**: Train SAE to find emotion-encoding features in T5 text embeddings

**Time**: 3 weeks total, ~10 minutes per experiment

---

## âœ… Prerequisites (Complete)

- [x] Phase 0 validated: Emotions ARE encoded in T5 embeddings (96% accuracy)
- [x] T5 embedding dataset ready: 100 samples in `results/t5_embeddings/`
- [x] SAE implementation: `src/models/sparse_autoencoder.py`
- [x] Training pipeline: `experiments/train_sae_on_t5_embeddings.py`
- [x] Analysis tools: `experiments/analyze_sae_features.py`

---

## ğŸš€ Week 1: Train Your First SAE (Start Here!)

### Step 1: Run Baseline Training (~10 minutes)

```bash
cd "/Users/lending/Documents/AI PRJ/MusicGen"
source venv/bin/activate
python3 experiments/train_sae_on_t5_embeddings.py
```

**What to expect**:
- Training progress bar with loss/sparsity metrics
- Model saved to `results/sae_training/sae_t5_exp8_l1e-03_[timestamp]/`
- Training curves plot saved

**Success indicators**:
- âœ… Reconstruction loss < 0.02
- âœ… L0 (active features) = 50-500
- âœ… Dead features < 100

---

### Step 2: Analyze Features (~2 minutes)

```bash
python3 experiments/analyze_sae_features.py
```

**What to expect**:
- Feature-emotion heatmap showing which features activate for which emotions
- List of emotion-selective features (selectivity > 2.0)
- Results saved to `results/sae_analysis/`

**Success indicators**:
- âœ… 50+ selective features found
- âœ… Features cluster by emotion in heatmap
- âœ… Top features have selectivity > 3.0

---

### Step 3: Hyperparameter Tuning

Edit `experiments/train_sae_on_t5_embeddings.py`:

```python
# Line 29: Try different L1 coefficients
CONFIG = {
    'l1_coefficient': 3e-3,  # Change this: 3e-4, 1e-3, 3e-3, 1e-2
    # ... rest stays same
}
```

Run training 4 times with different values. Pick the one with:
- Best reconstruction (MSE < 0.01)
- Good sparsity (L0 = 50-200)
- Interpretable features (selectivity > 3.0)

---

## ğŸ“Š Week 1 Expected Results

### Quantitative
- 50-150 emotion-selective features
- Reconstruction MSE: 0.005-0.015
- L0: 100-300 active features per sample
- Selectivity (best features): 3.0-6.0x

### Qualitative
You should see features that activate strongly for specific emotions:

**Example**:
- Feature 42: Activates 80% for "happy" prompts, 10% for others â†’ **Selectivity: 5.3x**
- Feature 108: Activates 75% for "sad" prompts, 12% for others â†’ **Selectivity: 5.1x**

---

## ğŸ¯ Decision Point: End of Week 1

**GO to Week 2 if**:
- âœ… Found 50+ selective features
- âœ… Reconstruction loss < 0.02
- âœ… Features make semantic sense (activate for related prompts)

**ITERATE Week 1 if**:
- âŒ Too few selective features â†’ Increase L1 coefficient
- âŒ Poor reconstruction â†’ Decrease L1 coefficient or increase expansion factor
- âŒ Too many dead features â†’ Reinit more frequently or scale up dataset

---

## ğŸ“ˆ Week 2: Scale Up (Optional but Recommended)

Generate 400-500 diverse prompts to improve feature quality:

1. Create prompt generation script
2. Extract T5 embeddings for all prompts
3. Retrain SAE on larger dataset
4. Expect: More robust, interpretable features

*Detailed instructions in [PHASE1_ROADMAP.md](PHASE1_ROADMAP.md)*

---

## ğŸ”¬ Week 3: Validate & Interpret

1. **Manual inspection**: Find what each top feature encodes
2. **Causal tests**: Clamp features and observe reconstruction changes
3. **Stability tests**: Train with different seeds, check if similar features emerge
4. **Final report**: Document findings and prepare for Phase 2

---

## ğŸ› Troubleshooting

### "ModuleNotFoundError: No module named 'models'"

```bash
# Make sure you're in the project directory
cd "/Users/lending/Documents/AI PRJ/MusicGen"
source venv/bin/activate
```

---

### Training loss not decreasing

**Symptoms**: Loss stays constant or increases

**Fixes**:
1. Check learning rate (try 3e-4 instead of 1e-3)
2. Decrease L1 coefficient (try 3e-4 instead of 1e-3)
3. Check data loaded correctly (should see 70-80 train samples)

---

### All features are dead

**Symptoms**: `dead_features` count equals total features (6144)

**Fixes**:
1. Decrease L1 coefficient significantly (try 1e-4)
2. Check encoder initialization scale (should be 0.1)
3. Verify ReLU activation is working

---

### Features not selective

**Symptoms**: All selectivity scores < 2.0

**Fixes**:
1. Increase L1 coefficient to force more sparsity
2. Scale up to 500-sample dataset (more diverse data)
3. Increase expansion factor to 12x or 16x

---

## ğŸ“ File Structure After Week 1

```
MusicGen/
â”œâ”€â”€ PHASE1_ROADMAP.md              â† Full roadmap
â”œâ”€â”€ PHASE1_QUICKSTART.md           â† This file
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ sparse_autoencoder.py  â† SAE implementation âœ…
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ dataset_utils.py       â† Data loading âœ…
â”‚
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ train_sae_on_t5_embeddings.py  â† Training script âœ…
â”‚   â”œâ”€â”€ analyze_sae_features.py        â† Analysis script âœ…
â”‚   â””â”€â”€ extract_t5_embeddings_at_scale.py  â† Dataset creation âœ…
â”‚
â””â”€â”€ results/
    â”œâ”€â”€ t5_embeddings/                 â† Input data (100 samples) âœ…
    â”‚   â”œâ”€â”€ embeddings.npy
    â”‚   â”œâ”€â”€ labels.npy
    â”‚   â””â”€â”€ metadata.json
    â”‚
    â”œâ”€â”€ sae_training/                  â† Training outputs ğŸ”²
    â”‚   â””â”€â”€ sae_t5_exp8_l1e-03_[timestamp]/
    â”‚       â”œâ”€â”€ best_model.pt
    â”‚       â”œâ”€â”€ config.json
    â”‚       â”œâ”€â”€ train_metrics.json
    â”‚       â”œâ”€â”€ val_metrics.json
    â”‚       â”œâ”€â”€ test_results.json
    â”‚       â””â”€â”€ training_curves.png
    â”‚
    â””â”€â”€ sae_analysis/                  â† Analysis outputs ğŸ”²
        â”œâ”€â”€ feature_emotion_heatmap.png
        â””â”€â”€ analysis_results.json
```

---

## ğŸ“ Key Concepts

### Sparse Autoencoder (SAE)
- **Input**: 768-dim T5 embedding
- **Hidden**: 6144-dim (8x overcomplete)
- **Output**: 768-dim reconstruction
- **Goal**: Find sparse, interpretable features

### Sparsity (L0)
- Number of active (non-zero) features per sample
- Target: 50-200 (1-3% of 6144)
- Too high â†’ Not interpretable (polysemantic)
- Too low â†’ Poor reconstruction

### Selectivity
- How specific a feature is to one emotion
- Formula: `max(activation_rate) / mean(activation_rate)`
- Selectivity > 2.0 â†’ Feature is emotion-selective
- Selectivity > 4.0 â†’ Feature is highly selective

### Dead Features
- Features that never activate during training
- Caused by too much sparsity or poor initialization
- Solution: Reinitialize periodically during training

---

## ğŸ¯ Success Criteria for Phase 1

**Minimum (to proceed to Phase 2)**:
- âœ… 50+ emotion-selective features (selectivity > 2.0)
- âœ… Reconstruction MSE < 0.02
- âœ… 10+ clearly interpretable features per emotion

**Ideal**:
- ğŸ 100+ selective features
- ğŸ Reconstruction MSE < 0.01
- ğŸ Selectivity > 4.0 for top features
- ğŸ Features generalize to unseen prompts

---

## ğŸ“š Next Steps After Phase 1

**Phase 2: Activation Steering** (Months 3-4)
- Use discovered features to control MusicGen
- Inject feature activations into T5 conditioning
- Generate music with steered emotions
- Validate with CLAP scores + human eval

**Phase 3: Causal Pathways** (Months 5-6)
- Map emotion â†’ acoustic features (tempo, mode, energy)
- Find causal pathways in MusicGen
- Compare to human music perception neuroscience

---

## â±ï¸ Time Estimates

| Task | Time | Cumulative |
|------|------|------------|
| Setup (already done) | 0 min | 0 min |
| Baseline training | 10 min | 10 min |
| Feature analysis | 2 min | 12 min |
| Hyperparameter sweep (4 runs) | 40 min | 52 min |
| Best model analysis | 2 min | 54 min |
| **Week 1 Total** | **~1 hour** | |
| Scale up dataset | 30 min | |
| Retrain on 500 samples | 15 min | |
| **Week 2 Total** | **~1 hour** | |
| Manual interpretation | 2 hours | |
| Causal validation | 1 hour | |
| Report writing | 2 hours | |
| **Week 3 Total** | **~5 hours** | |
| **Phase 1 Total** | **~7 hours** | |

---

## ğŸš€ Start Now!

```bash
cd "/Users/lending/Documents/AI PRJ/MusicGen"
source venv/bin/activate
python3 experiments/train_sae_on_t5_embeddings.py
```

Watch the progress bar. In 10 minutes, you'll have your first SAE trained! ğŸ‰

---

*For detailed technical information, see [PHASE1_ROADMAP.md](PHASE1_ROADMAP.md)*
*For Phase 0 results, see test_text_embeddings.py and extract_t5_embeddings_at_scale.py outputs*
